# Summarize the data for Financial Literacy and Treatments
s2 <- df %>%
group_by(financial_lit_b, Treatments) %>%
summarise(N = length(unique(uemail)), .groups = "drop")
names(s2) <- names
View(s2)
s2 <- s2[-c(13:16), ]  # Remove extraneous rows
# Perform Chi-squared test for Financial Literacy
contingency_table <- xtabs(N ~ Variable + Treatment, data = s2)
chi.s2 <- chisq.test(contingency_table)
chi.s2
s3 <- df %>%
group_by(educ_eng, Treatments) %>%
summarise(N = length(unique(uemail)), .groups = "drop")
names(s3) <- names
# Perform Chi-squared test for Education
contingency_table <- xtabs(N ~ Variable + Treatment, data = s3)
chi.s3 <- chisq.test(contingency_table)
chi.s3
s4 <- df %>%
group_by(private_health, Treatments) %>%
summarise(N = length(unique(uemail)), .groups = "drop")
names(s4) <- names
contingency_table <- xtabs(N ~ Variable + Treatment, data = s4)
chi.s4 <- chisq.test(contingency_table)
# Combine summaries into a single table
tbl <- bind_rows(s1, s2, s3, s4)
View(s1)
View(s2)
View(s3)
View(s4)
View(s3)
View(s2)
View(s1)
s11 <- make_variable_character(s1)
make_variable_character <- function(df) {
df$Variable <- as.character(df$Variable)
return(df)
}
s11 <- make_variable_character(s1)
s12 <- make_variable_character(s2)
s13 <- make_variable_character(s3)
s14 <- make_variable_character(s4)
View(s2)
View(s12)
View(s1)
View(s11)
tbl <- bind_rows(s1, s2, s3, s4)
s1 <- make_variable_character(s1)
s2 <- make_variable_character(s2)
s3 <- make_variable_character(s3)
s4 <- make_variable_character(s4)
# Combine summaries into a single table
tbl <- bind_rows(s1, s2, s3, s4)
# Pivot table to wide format for summary
tbl_wide <- tbl %>%
pivot_wider(names_from = Treatment, values_from = N) %>%
mutate(Total = rowSums(across(where(is.numeric)), na.rm = TRUE))
# Add percentages for each Treatment group
tbl_wide <- tbl_wide %>%
mutate(
`% Baseline` = round(Baseline / Total, 4) * 100,
`% Profile` = round(Perfil / Total, 4) * 100,
`% Video` = round(Video / Total, 4) * 100,
`% Profile and Video` = round(VideoPerfil / Total, 4) * 100
)
# Summarize data for Age (mean and SD)
s5 <- df %>%
group_by(Treatments) %>%
summarise(
Age_mean = round(mean(Age, na.rm = TRUE), 2),
Age_sd = round(sd(Age, na.rm = TRUE), 2),
.groups = "drop"
) %>%
pivot_longer(cols = c(Age_mean, Age_sd), names_to = "Variable", values_to = "Value") %>%
pivot_wider(names_from = Treatments, values_from = Value)
# Perform ANOVA for Age across Treatments
anova_result <- aov(Age ~ Treatments, data = df)
anova_summary <- summary(anova_result)
print(anova_summary)
p_value_anova <- anova_summary[[1]]$`Pr(>F)`[1]
# Add ANOVA p-value to Age summary
s5$p_value <- ifelse(s5$Variable == "Age_mean", round(p_value_anova, 4), NA)
# Combine Age summary with previous table
tbl_final <- bind_rows(tbl_wide, s5)
# Add variable names to the table
tbl_final$Variable <- c(
"Female", "Male", "Low Fin. Lit.", "Mid Fin. Lit.", "High Fin. Lit.",
"Post-graduate degree", "Primary or high-school degree", "University degree",
"Public Health or other", "Private healthcare", "Age (mean)", "Age (sd)"
)
# Compute p-values for all variables
p_values <- c(
chi.s1$p.value, chi.s2$p.value, chi.s3$p.value, chi.s4$p.value, NA  # NA for Age SD
)
p_values_repeated <- c(
rep(p_values[1], 2),  # s1 has two rows (Female, Male)
rep(p_values[2], 3),  # s2 has three rows (Financial Literacy)
rep(p_values[3], 3),  # s3 has three rows (Education)
rep(p_values[4], 2),  # s4 has two rows (Health)
rep(p_values[5], 2)   # s5 has two rows (Age mean and Age SD)
)
tbl_final$`P-value` <- round(p_values_repeated, 4)
# Rename columns for final table
colnames(tbl_final) <- c(
"Variable", "Baseline", "Profile", "Video", "Profile and Video",
"Total", "% Baseline", "% Profile", "% Video", "% Profile and Video", "P-value"
)
# Export table to LaTeX
xt <- xtable(tbl_final)
#print(xt, type = "latex", file = paste0(path_github, "/Outputs/balance_numbers_lab.tex"),
floating = FALSE, include.rownames = FALSE)
xt
# Define consistent column names
names <- c("Variable", "Treatment", "N")
# Summarize the data for Gender and Treatments
s1 <- df %>%
group_by(Gender, Treatments) %>%
summarise(N = length(unique(uemail)), .groups = "drop")
names(s1) <- names
# Perform Chi-squared test for Gender
contingency_table <- xtabs(N ~ Variable + Treatment, data = s1)
chi.s1 <- chisq.test(contingency_table)
# Summarize the data for Financial Literacy and Treatments
s2 <- df %>%
group_by(financial_lit_b, Treatments) %>%
summarise(N = length(unique(uemail)), .groups = "drop")
names(s2) <- names
s2 <- s2[-c(13:16), ]  # Remove extraneous rows
# Perform Chi-squared test for Financial Literacy
contingency_table <- xtabs(N ~ Variable + Treatment, data = s2)
chi.s2 <- chisq.test(contingency_table)
# Summarize the data for Education and Treatments
s3 <- df %>%
group_by(educ_eng, Treatments) %>%
summarise(N = length(unique(uemail)), .groups = "drop")
names(s3) <- names
# Perform Chi-squared test for Education
contingency_table <- xtabs(N ~ Variable + Treatment, data = s3)
chi.s3 <- chisq.test(contingency_table)
# Summarize the data for Health and Treatments
s4 <- df %>%
group_by(private_health, Treatments) %>%
summarise(N = length(unique(uemail)), .groups = "drop")
names(s4) <- names
# Perform Chi-squared test for Health
contingency_table <- xtabs(N ~ Variable + Treatment, data = s4)
chi.s4 <- chisq.test(contingency_table)
# Function to ensure consistent Variable type (character)
make_variable_character <- function(df) {
df$Variable <- as.character(df$Variable)
return(df)
}
s1 <- make_variable_character(s1)
s2 <- make_variable_character(s2)
s3 <- make_variable_character(s3)
s4 <- make_variable_character(s4)
# Combine summaries into a single table
tbl <- bind_rows(s1, s2, s3, s4)
# Pivot table to wide format for summary
tbl_wide <- tbl %>%
pivot_wider(names_from = Treatment, values_from = N) %>%
mutate(Total = rowSums(across(where(is.numeric)), na.rm = TRUE))
# Add percentages for each Treatment group
tbl_wide <- tbl_wide %>%
mutate(
`% Baseline` = round(Baseline / Total, 4) * 100,
`% Profile` = round(Perfil / Total, 4) * 100,
`% Video` = round(Video / Total, 4) * 100,
`% Profile and Video` = round(VideoPerfil / Total, 4) * 100
)
# Summarize data for Age (mean and SD)
s5 <- df %>%
group_by(Treatments) %>%
summarise(
Age_mean = round(mean(Age, na.rm = TRUE), 2),
Age_sd = round(sd(Age, na.rm = TRUE), 2),
.groups = "drop"
) %>%
pivot_longer(cols = c(Age_mean, Age_sd), names_to = "Variable", values_to = "Value") %>%
pivot_wider(names_from = Treatments, values_from = Value)
# Perform ANOVA for Age across Treatments
anova_result <- aov(Age ~ Treatments, data = df)
anova_summary <- summary(anova_result)
print(anova_summary)
p_value_anova <- anova_summary[[1]]$`Pr(>F)`[1]
# Add ANOVA p-value to Age summary
s5$p_value <- ifelse(s5$Variable == "Age_mean", round(p_value_anova, 4), NA)
# Combine Age summary with previous table
tbl_final <- bind_rows(tbl_wide, s5)
# Add variable names to the table
tbl_final$Variable <- c(
"Female", "Male", "Low Fin. Lit.", "Mid Fin. Lit.", "High Fin. Lit.",
"Post-graduate degree", "Primary or high-school degree", "University degree",
"Public Health or other", "Private healthcare", "Age (mean)", "Age (sd)"
)
# Compute p-values for all variables
p_values <- c(
chi.s1$p.value, chi.s2$p.value, chi.s3$p.value, chi.s4$p.value, NA  # NA for Age SD
)
p_values_repeated <- c(
rep(p_values[1], 2),  # s1 has two rows (Female, Male)
rep(p_values[2], 3),  # s2 has three rows (Financial Literacy)
rep(p_values[3], 3),  # s3 has three rows (Education)
rep(p_values[4], 2),  # s4 has two rows (Health)
rep(p_values[5], 2)   # s5 has two rows (Age mean and Age SD)
)
tbl_final$`P-value` <- round(p_values_repeated, 4)
# Rename columns for final table
colnames(tbl_final) <- c(
"Variable", "Baseline", "Profile", "Video", "Profile and Video",
"Total", "% Baseline", "% Profile", "% Video", "% Profile and Video", "P-value"
)
# Export table to LaTeX
xt <- xtable(tbl_final)
print(xt, type = "latex", file = paste0(path_github, "/Outputs/balance_numbers_lab.tex"),
floating = FALSE, include.rownames = FALSE)
# Clean up the environment
rm(tbl, tbl_wide, s1, s2, s3, s4, s5, tbl_final)
library(stargazer)
library(MASS)
library(broom)
library(ggpubr)
library(naniar)
library(nnet)
library(lmtest)
library(sandwich)
rm(list=ls())
path_github <- "C:/Users/DCCS2/Documents/GitHub/Pensions-Website-Design/Data and analysis/Lab/"
path_datos<-"C:/Users/DCCS2/Documents/GitHub/Pensions-Website-Design/Data and analysis/Lab/Lab Data/Surveys and websites/"
df <- readRDS(paste0(path_datos, "lab_data.rds"))
df.f<-df[!is.na(df$correct_response),]
df.en <- readRDS(paste0(path_datos, "encuestas_clean.rds"))
path_datos <- "C:/Users/DCCS2/Dropbox/Sitios web/Datos Laboratorio/Videos/"
path_github <- "C:/Users/DCCS2/Documents/GitHub/Pensions-Website-Design/"
df<-read.csv(paste0(path_datos,"dataset_con_columnas_2024.csv"))
View(df)
data_webA <- load_webA();
# Updated power calculation function using OLS model
set.seed(23658)
power <- function(rep, esize, N) {
pv <- rep(NA, rep)  # Initialize p-values storage
for (i in 1:rep) {
# Generate the data
mydata <- data.frame(samegroup = rep(c(TRUE, FALSE), each = N / 2))
# Add normally distributed errors with sigma = 0.2
mydata$given <- 4.6 + mydata$samegroup * esize + rnorm(N, mean = 0, sd = 1)
# Fit the linear model
model <- lm(given ~ samegroup, data = mydata)
# Extract p-value for 'samegroup' coefficient
p <- summary(model)$coefficients["samegroupTRUE", "Pr(>|t|)"]
# Store p-value
pv[i] <- p
}
# Calculate power
power <- sum(pv < 0.05) / length(pv)
return(power)
}
# Single calculation with a fixed N
power(rep = 100, esize = 0.8, N = 30)
# Loop over multiple N values
N <- seq(10, 200, 2)
M <- length(N)
N.power <- rep(NA, M)
for (i in 1:M) {
N.power[i] <- power(rep = 100, esize = 0.8, N = N[i])
}
# Plot the power calculations
plot(N.power, N / 2, main = "Power calculations", ylab = "Number of obs in each group", xlab = "Power")
###############################
############# Multiple betas
###############################
# Power calculation function using OLS model
# Define the updated power function with OLS model
set.seed(23569)
power <- function(rep, esize, N) {
pv <- rep(NA, rep)
for (i in 1:rep) {
mydata <- data.frame(samegroup = rep(c(TRUE, FALSE), each = N / 2))
mydata$given <- 4.6 + mydata$samegroup * esize + rnorm(N, mean = 0, sd = 1)
model <- lm(given ~ samegroup, data = mydata)
p <- summary(model)$coefficients["samegroupTRUE", "Pr(>|t|)"]
pv[i] <- p
}
power <- sum(pv < 0.05) / length(pv)
return(power)
}
# Set up parameters for the simulation
N <- seq(10, 100, 2)  # Sample sizes to test
effects <- seq(0.6, 0.9, by = 0.1)  # Different effect sizes to test
M <- length(N)
K <- length(effects)
# Initialize a matrix to store power calculations for each (N, effect size) pair
ne.power <- matrix(NA, nrow = M, ncol = K)
# Calculate power for each effect size and sample size
for (i in 1:M) {
for (j in 1:K) {
ne.power[i, j] <- power(rep = 500, esize = effects[j], N = N[i])
}
}
# Plot the results
par(mfrow = c(3, 2))  # Set up a 3x2 plot layout
colors <- c("red", "blue", "green", "purple", "springgreen4", "grey30")  # Define colors for each plot
for (j in 1:K) {
plot(ne.power[, j], N / 2, col = colors[j], main = paste("Effect =", effects[j]),
xlim = c(0, 1), ylab = "Number of obs per group", xlab = "Power")
abline(v = 0.8, col = "red", lty = 2)  # Add a red vertical dashed line at x = 0.8
}
# Plot the results
par(mfrow = c(2, 2))  # Set up a 3x2 plot layout
colors <- c("red", "blue", "green", "purple", "springgreen4", "grey30")  # Define colors for each plot
for (j in 1:K) {
plot(ne.power[, j], N / 2, col = colors[j], main = paste("Effect =", effects[j]),
xlim = c(0, 1), ylab = "Number of obs per group", xlab = "Power")
abline(v = 0.8, col = "red", lty = 2)  # Add a red vertical dashed line at x = 0.8
}
library(foreign)
library(dplyr)
library(stringr)
library(ggplot2)
library(gridExtra)
library(tidyr)
rm(list=ls())
path_github <-"C:/Users/DCCS2/Documents/GitHub/Multi-level-collective-action-in-small-scale-fisheries/Exptal Sessions/R/"
path_datos<-"C:/Users/DCCS2/Dropbox/CICS/Experiments/Islitas/Data/Sessions"
setwd(path_github)
datos_csv<-"datos_piloto_islitas.csv"
# List all CSV files in the specified folder
file_list <- list.files(path = path_datos, pattern = "\\.csv$", full.names = TRUE)
# Read each CSV file and combine them into one data frame
df<- do.call(rbind, lapply(file_list, read.csv))
df$gid.treat<-df$participant.zonaT2
df$gid.amerb<-paste0(df$participant.caleta, ".",df$participant.zonaT2, ".",df$participant.id_caleta)
#df$gid.amerb <- gsub(" ", ".", df$ugid)
save(df, file = paste0(path_datos, "/Datos_islitas.Rdata"))
rm(list=ls())
path_github <-"C:/Users/DCCS2/Documents/GitHub/Multi-level-collective-action-in-small-scale-fisheries/Exptal Sessions/R/"
path_datos<-"C:/Users/DCCS2/Dropbox/CICS/Experiments/Islitas/Data/Sessions"
setwd(path_github)
load(paste0(path_datos, "/Datos_islitas.Rdata"))
#################################################
################# Subsets #######################
#################################################
# T1
rounds <- 1:8  # Sequence from 1 to 10
treats <- c("T1")  # Time periods T1 and T2
vars <- c("amerb", "libre")  # Extraction types
# Generate the list of variables using expand.grid to generate all combinations
combinations <- expand.grid(treats, rounds, vars)
# Create the final object with formatted strings
variable_names1 <- paste0(
"", combinations$Var1, "juegoalgas.", combinations$Var2,
".player.", combinations$Var1, "_extraccion_", combinations$Var3
)
# T2"
rounds <- 1:8  # Sequence from 1 to 10
treats <- c("T2")  # Time periods T1 and T2
vars <- c("amerb", "metat")  # Extraction types
# Generate the list of variables using expand.grid to generate all combinations
combinations <- expand.grid(treats, rounds, vars)
# Create the final object with formatted strings
variable_names2 <- paste0(
"", combinations$Var1, "juegoalgas.", combinations$Var2,
".player.", combinations$Var1, "_extraccion_", combinations$Var3
)
# Print or use the variable_names
variable_names<-c(variable_names1, variable_names2, "gid.amerb", "gid.treat")
##### Treatment variables subset
dfs<-(df[, variable_names])
#### Long data frame all observations
dfs_long <- dfs %>%
pivot_longer(
cols = starts_with("T"),   # All columns starting with "T" (T1 and T2 variables)
names_to = c("treatment", "round", "area"),  # Split the names into three parts
names_pattern = "(T\\d)juegoalgas\\.(\\d+)\\.player\\..+_extraccion_(.+)",  # Regex to extract treatment, round, and variable
values_to = "extraction"   # Name of the column for values
) %>%
mutate(round = as.integer(round))  # Ensure round is numeric
# Mean by treatment and area, for each round for diff-in-diff
rm <- dfs_long %>%
group_by(treatment, area, round) %>%  # Group by treatment and variable
summarise(mean_extraction = mean(extraction, na.rm = TRUE))  # Calculate mean and handle missing values
#Belief Columns
names(df)
df$beliefsT1inicial.1.player.T1_belief_caleta_en_amerb_ini
df$beliefsT1final.1.player.T1_belief_caleta_en_libre_fin
df$beliefsT1final.1.player.T1_belief_pm_en_libre_fin
df$beliefsT1inicial.1.player.T1_belief_caleta_en_libre_ini
belief_columns <- grep("belief", colnames(df), value = TRUE, ignore.case = TRUE)
# Now filter to keep only the ones that end in "_ini" or "_fin"
filtered_belief_columns <- grep("_ini$|_fin$|id", belief_columns, value = TRUE, ignore.case = TRUE)
# View the result
print(filtered_belief_columns)
View(df[,c(filtered_belief_columns,  "gid.treat", "gid.amerb")])
#################################################
############### Data Analysis ###################
#################################################
#Descriptive statistics
20000+mean(df$participant.payoff, na.rm=T)
summary(df$participant.payoff, na.rm=T)
table(df$T2juegoalgas.1.player.T2_grupo_mixto)
table(df$participant.grupo_amerb)
rm_wide <- rm %>%
mutate(area = ifelse(area %in% c("metat", "libre"), "other_area", "amerb")) %>%  # Update area values
pivot_wider(
names_from = treatment,  # Create columns based on treatment
values_from = mean_extraction  # Populate with mean_extraction values
) %>%
mutate(diff = T2 - T1)  # Add the difference between T2 and T1
pdid<-ggplot(rm_wide, aes(x = round, y = diff, color = area, group = area)) +
geom_line() +  # Line plot for each extraction type
geom_point() +  # Add points to indicate the data
labs(
title = "Difference between T2 and T1 per Round",
x = "Round",
y = "Difference (T2 - T1)",
color = "Extraction Area"
) +
scale_x_continuous(breaks = 1:10) +
theme_minimal() +  # Use a minimal theme for better visualization
theme(legend.position = "top")
pdid
diff_area <- rm %>%
pivot_wider(
names_from = area,        # Spread area (libre, metat, amerb) into separate columns
values_from = mean_extraction  # The mean extraction values
) %>%
arrange(round) %>%
mutate(otra_zona = coalesce(libre, metat),
diff = otra_zona - amerb)  # Calculate the difference between T1 and T2
# Step 3: Plot the difference per round for amerb and libre
pdiff<-ggplot(diff_area , aes(x = round, y = diff, color = treatment, group = treatment)) +
geom_line() +  # Line plot for each extraction type
geom_point() +  # Add points to indicate the data
labs(
title = "In and out-group bias ",
x = "Round",
y = "Difference (Otra zona- Amerb)",
color = "Tratamiento"
) +
scale_x_continuous(breaks = 1:10) +
theme_minimal() +  # Use a minimal theme for better visualization
theme(legend.position = "top")
pdiff
ba<-ggplot(df, aes(x = beliefsT1inicial.1.player.T1_belief_caleta_en_amerb_ini,
y = T1juegoalgas.1.player.T1_extraccion_amerb)) +
geom_point() +  # Scatter plot points
geom_smooth(method = "lm", se = TRUE) +  # Adds lm line with confidence intervals
labs(
title = "Extraction AMERB given Beliefs - Ingroup",
x = "Beliefs Ingroup in Amerb - T1 Round 0",
y = "Player Extraction Amerb - T1 Round 1"
) +
theme_minimal()
ba
lm<-lm(T1juegoalgas.1.player.T1_extraccion_amerb ~ beliefsT1inicial.1.player.T1_belief_caleta_en_amerb_ini, data=df)
summary(lm)
lm1<-lm(T1juegoalgas.1.player.T1_extraccion_libre ~ beliefsT1inicial.1.player.T1_belief_caleta_en_libre_ini, data=df)
summary(lm1)
lm2<-lm(T1juegoalgas.1.player.T1_extraccion_libre ~ beliefsT1inicial.1.player.T1_belief_pm_en_libre_ini, data=df)
summary(lm2)
boa<-ggplot(df_combined, aes(x = Beliefs, y = Extraction, color = Type, shape = Type)) +
geom_point() +
geom_smooth(method = "lm", se = TRUE) +  # Adds lm line with confidence intervals for each type
labs(
title = "Extraction Open Access given Ingroup and Outgroup Beliefs",
x = "Beliefs in Libre - Ingroup and Outgroup",
y = "Player Extraction Libre"
) +
theme_minimal() +
scale_color_manual(values = c("Ingroup" = "blue", "Outgroup" = "red")) +  # Optional color customization
scale_shape_manual(values = c("Ingroup" = 16, "Outgroup" = 17))  # Optional shape customization
df_combined <- rbind(
data.frame(
Beliefs = df$beliefsT1inicial.1.player.T1_belief_caleta_en_libre_ini,
Extraction = df$T1juegoalgas.1.player.T1_extraccion_libre,
Type = "Ingroup"
),
data.frame(
Beliefs = df$beliefsT1inicial.1.player.T1_belief_pm_en_libre_ini,
Extraction = df$T1juegoalgas.1.player.T1_extraccion_libre,
Type = "Outgroup"
)
)
# Scatter plot with different color and shape for each belief type
boa<-ggplot(df_combined, aes(x = Beliefs, y = Extraction, color = Type, shape = Type)) +
geom_point() +
geom_smooth(method = "lm", se = TRUE) +  # Adds lm line with confidence intervals for each type
labs(
title = "Extraction Open Access given Ingroup and Outgroup Beliefs",
x = "Beliefs in Libre - Ingroup and Outgroup",
y = "Player Extraction Libre"
) +
theme_minimal() +
scale_color_manual(values = c("Ingroup" = "blue", "Outgroup" = "red")) +  # Optional color customization
scale_shape_manual(values = c("Ingroup" = 16, "Outgroup" = 17))  # Optional shape customization
boa
lm3<-lm(T1juegoalgas.1.player.T1_extraccion_libre ~ beliefsT1inicial.1.player.T1_belief_caleta_en_libre_ini+ beliefsT1inicial.1.player.T1_belief_pm_en_libre_ini , data=df)
summary(lm3)
table(df$gid.amerb)
table(df$survey1.1.player.confianza_caleta)
table(df$survey1.1.player.conflicto_caleta)
table(df$survey1.1.player.confianza_caleta)
table(df$survey1.1.player.confianza_pm)
table(df$survey2.1.player.confianza_caleta_conocida1)
table(df$survey2.1.player.confianza_caleta_conocida2)
48+35+9+8
76+64+18+6
table(df$survey1.1.player.conflicto_caleta)
table(df$survey1.1.player.conflicto_pm)
table(df$survey2.1.player.conflicto_caleta_conocida1)
table(df$survey2.1.player.conflicto_caleta_conocida2)
